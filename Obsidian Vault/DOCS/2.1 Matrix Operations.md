# 2.1 Matrix Operations
2023-04-18 | 21:31
{Subject}:[[MTHS 212]]
{Section}:[[2.0 Matrix Algebra]]
{Tags}: #Mathematics #LinearAlgebra 
{Related}:

--- 
### Representations of a matrix

A `matrix` may be written in terms of its column vectors as

$$ A = \begin{bmatrix}a_1 & a_2 & ... & a_n \end{bmatrix} $$

or in terms of its entries as

$$ A = \begin{bmatrix}a_{11} & ... & a_{1n}\\ \vdots & \ddots & \vdots \\ a_{m1} & ... & a_{mn} \end{bmatrix} $$

### Terminology

-   The `diagonal elements` of a matrix are the elements: $a_{11},a_{22},...,a_{nn}$
-   A `diagonal matrix` is a square matrix all of whose non-diagonal entries are zeros.
-   A `zero matrix` is a matrix with all entries zeros

### Definitions

-   Two matrices are `equal` if all corresponding entries are equal.
-   To find the `sum` of two matrices of the same size, we add corresponding entries.
-   The `scalar product` (`scalar multiple`) $rA$ of a matrix $A$ with a scalar $r$, is that matrix that is obtained if every entry of $A$ is multiplied by the scalar $r$.

### Theorem 1

Let $A,B$ and $C$ be matrices of the same size, $r$ and $s$ scalars.

1.  $A+B=B+A$ `(commutative law)`
2.  $(A+B)+C = A+(B+C)$ `(associative law)`
3.  $A+0=A$ `(zero element)`
4.  $r(A+B)=rA+rB$ `(distributive law)`
5.  $(r+s)A = rA+sA$ `(distributive law)`
6.  $r(sA)=(rs)A$ `(associative law)`

### Definition

1.  If $A$ is an $m \times n$ matrix with and $B$ is an $n\times p$ matrix with columns: $\vec b_1,\vec b_2,...,\vec b_p$
2.  Then the product $AB$ is the $m \times p$ matrix whose columns are: $A\vec b_1,A\vec b_2,...,A\vec b_p$

$$ 𝐴B =A\begin{bmatrix} \vec 𝒃_1 & \vec 𝒃_2& … & \vec 𝒃_𝑝 \end{bmatrix} = \begin{bmatrix} 𝐴\vec 𝒃_1 & 𝐴\vec 𝒃_2 & … & 𝐴\vec 𝒃_𝑝 \end{bmatrix} $$

### Row-column rule for computing $AB$

If the product $A$ is defined, then the entry in row $i$ and column $j$ of $A$ is the sum of the products of corresponding entries from row $i$ of $A$ and column $j$ of $B$.

If $A$ is $m \times n$ and $(AB)_{ij}$ denotes the $(i,j)$-th entry of $AB$, then

$$ (AB)_{ij}=a_{i1}b_{1j} + a_{i2}b_{2j}+...+a_{jn}b_{nj} $$

### Theorem 2

Let $A$ be an $m \times n$ matrix, and let $B$ and $C$ have sizes for which the indicated sums and products are defined.

1.  $A(BC)=(AB)C$ `(associative law of multiplication)`
2.  $A(B+C)=AB+AC$ `(left distributive law)`
3.  $(B+C)A=BA+CA$ `(right distributive law)`
4.  $r(AB) =(rA)B=A(rB)$ for any scalar $r$
5.  $I_mA=A=AI_n$ `(identity for matrix multiplication)`

### Definitions

-   Let $A$ be an $n \times n$ matrix and $k$ a positive integer. We define: $A^k=A~...~A$ ($k$ times)
-   Let A be an $m \times n$ matrix. The `transpose` $A^T$ of $A$ is the matrix whose columns are formed by taking the corresponding rows of $A$.

### Properties of the transpose

$A$ and B are matrices of appropriate sizes.

-   $(A^T)^T=A$
-   $(A+B)^T=A^T+B^T$
-   $(rA)^T=rA^T$ `for and scalar $r$`
-   $(AB)^T=B^TA^T$
--- 
{Efundi Lecture Notes}: [Matrix Operations](https://efundi.nwu.ac.za/access/content/group/dcb035b6-0c04-4a4b-ae6d-f100a884060e/Lecture%20notes/Mr%20Majozi/MTHS%20212%20Leergedeelte%203.1.pdf)